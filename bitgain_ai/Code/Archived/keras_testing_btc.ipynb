{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\ngancitano\\AppData\\Roaming\\Python\\Python36\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# TODO: convert from \"binary on profitable\" to \"regression on change percent\"\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import Model\n",
    "from keras_pandas import lib\n",
    "from keras_pandas.Automater import Automater\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import stockstats as ss\n",
    "\n",
    "#import util\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import argv,exit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense,Dropout,GRU,Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential  \n",
    "from keras.layers.core import Dense, Activation  \n",
    "from keras.layers.recurrent import LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def _load_data(data, n_prev=10):  \n",
    "    \"\"\"\n",
    "    data should be pd.DataFrame()\n",
    "    \"\"\"\n",
    "    docX, docY = [], []\n",
    "    for i in range(len(data)-n_prev):\n",
    "        docX.append(data.iloc[i:i+n_prev].as_matrix())\n",
    "        docY.append(data.iloc[i+n_prev].as_matrix())\n",
    "    alsX = np.array(docX)\n",
    "    alsY = np.array(docY)\n",
    "    return alsX, alsY\n",
    "\n",
    "def time_series_split(df, test_size=0.2):  \n",
    "    \"\"\"\n",
    "    This just splits data to training and testing parts\n",
    "    \"\"\"\n",
    "    ntrn = round(len(df) * (1 - test_size))\n",
    "\n",
    "    n_prex = 0\n",
    "    X_train, y_train = _load_data(df.iloc[0:ntrn])\n",
    "    X_test, y_test = _load_data(df.iloc[ntrn:])\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "FEES = 0\n",
    "def profitable(x):\n",
    "    if x[\"change\"] >= (0 + FEES):\n",
    "        return 1\n",
    "    elif x[\"change\"] <= (0 - FEES):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   timestamp    open    high     low   close  volume    change\n",
      "0        4134  1420681200  348.77  348.77  340.62  340.62    0.03 -0.020228\n",
      "1        4135  1420681260  333.73  333.73  333.73  333.73    0.01 -0.001348\n",
      "2        4136  1420681320  329.84  333.28  313.42  333.28    0.03 -0.051278\n",
      "3        4137  1420681380  273.20  316.19  273.20  316.19    0.02  0.111294\n",
      "4        4138  1420681440  323.27  351.38  323.27  351.38    0.02 -0.064546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "c:\\python36\\lib\\site-packages\\stockstats.py:387: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  lambda x: np.fabs(x - x.mean()).mean())\n",
      "c:\\python36\\lib\\site-packages\\numpy\\core\\fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "951687\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "    unnamed: 0   timestamp    open    high     low   close  volume    change  \\\n",
      "10        4144  1420681800  303.53  333.28  290.18  333.28    0.03 -0.012752   \n",
      "11        4145  1420681860  278.49  329.03  278.49  329.03    0.02 -0.030848   \n",
      "12        4146  1420681920  333.45  333.45  318.88  318.88    0.02  0.023802   \n",
      "13        4147  1420681980  328.39  328.39  326.47  326.47    0.02  0.016755   \n",
      "14        4148  1420682040  272.63  331.94  272.63  331.94    0.02 -0.059860   \n",
      "\n",
      "    close_26_ema      macd    ...            mdi      dx_14         dx  \\\n",
      "10    327.929525 -1.541712    ...      26.177437   5.151284   5.151284   \n",
      "11    328.064736 -1.207150    ...      25.466982  14.876437  14.876437   \n",
      "12    326.988746 -1.516372    ...      23.284625   9.957779   9.957779   \n",
      "13    326.930484 -1.288247    ...      21.571999   9.957779   9.957779   \n",
      "14    327.472391 -0.775171    ...      38.516206  46.858159  46.858159   \n",
      "\n",
      "     dx_6_ema        adx  adx_6_ema       adxr      trix  trix_9_sma  \\\n",
      "10  25.358428  25.358428  43.224476  43.224476 -0.201522   -0.185384   \n",
      "11  22.287746  22.287746  37.091095  37.091095 -0.198492   -0.180057   \n",
      "12  18.701644  18.701644  31.742627  31.742627 -0.202234   -0.162872   \n",
      "13  16.171520  16.171520  27.236973  27.236973 -0.196592   -0.162504   \n",
      "14  25.018750  25.018750  26.597439  26.597439 -0.177940   -0.165336   \n",
      "\n",
      "           vr  \n",
      "10  40.000000  \n",
      "11  36.363636  \n",
      "12  45.454545  \n",
      "13  54.545455  \n",
      "14  50.000000  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "#observations = lib.load_titanic()\n",
    "btc = pd.read_csv(\"../Data/coinbase_minutely.csv\")\n",
    "#btc = pd.read_csv(\"../Data/SPY_in_theory_from_1-01-00_to_1-26-19.csv\")\n",
    "print(btc.head())\n",
    "btc = ss.StockDataFrame.retype(btc) #coerces df into StockDataFrame again\n",
    "\n",
    "#calculates and appends TA indicators to stock\n",
    "\n",
    "btc['macd'] # calculate MACD indicator for the entire \"btc\" df and automatically appends to new column\n",
    "btc['volume_delta']\n",
    "btc['open_-1_r']\n",
    "btc['cr']\n",
    "btc['cr-ma1']\n",
    "btc['cr-ma2']\n",
    "btc['cr-ma3']\n",
    "btc[\"rsi_6\"]\n",
    "btc[\"rsi_12\"]\n",
    "btc[\"wr_10\"]\n",
    "btc[\"cci\"]\n",
    "btc['tr']\n",
    "btc['atr']\n",
    "btc['dma']\n",
    "btc['pdi']\n",
    "btc['mdi']\n",
    "btc['dx']\n",
    "btc['adx']\n",
    "btc['adxr']\n",
    "btc['trix']\n",
    "btc['trix_9_sma']\n",
    "btc['vr']\n",
    "btc.head()\n",
    "\n",
    "#apply profitable function then clean dataset again\n",
    "#btc[\"profitable\"] = btc.apply(profitable, axis=1) #adding column \"profitable\" where +1 represents price went up and 0 represents price went down\n",
    "#btc[\"profitable\"] = btc[\"profitable\"].shift(-1) #shifts \"profitable\" target column up 1 so current days stats predict tomorrow's profitability \n",
    "\n",
    "btc = btc[1:len(btc.index)-1] #removes first & last entry that now has NaN \"profitable\" column\n",
    "btc = btc.dropna() #removes all rows containing any NaN values\n",
    "print(len(btc))\n",
    "\n",
    "\n",
    "btc = pd.DataFrame(btc)\n",
    "change_list = btc['change'].values\n",
    "#btc = btc.drop([\"change\"], axis=1).iloc[:,1:]\n",
    "print(type(btc))\n",
    "print(btc.head())\n",
    "\n",
    "winsound.Beep(600,1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(951687, 57)\n",
      "(666180, 49)\n"
     ]
    }
   ],
   "source": [
    "print(btc.shape)\n",
    "print(x_std_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X stuff\n",
      "(666180, 49)\n",
      "(285507, 49)\n",
      "951687\n",
      "Y stuff\n",
      "(666180,)\n",
      "0.0022867570435918232\n",
      "0.0006331066772443413\n"
     ]
    }
   ],
   "source": [
    "#create train-test sets, then std'ize and check lengths\n",
    "\n",
    "#btc = btc.drop([\"change\"], axis=1)\n",
    "x = btc.iloc[:, 8:].values\n",
    "y = btc.iloc[:, 7].values*100\n",
    "#y = stock_month[\"profitable\"]\n",
    "#x = stock_month.drop([\"profitable\", \"change\"], axis=1) #move drop until after split to track data for backtesting\n",
    "\n",
    "import random\n",
    "RANDOM_STATE = 123\n",
    "random.seed(RANDOM_STATE)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = .3,random_state = RANDOM_STATE)\n",
    "'''\n",
    "training_split = 0.75\n",
    "x_train = x[:int(len(x)*training_split)]\n",
    "x_test = x[int(len(x)*training_split):]\n",
    "y_train = y[:int(len(y)*training_split)]\n",
    "y_test = y[int(len(y)*training_split):]\n",
    "'''\n",
    "sc = StandardScaler()\n",
    "x_std_train = sc.fit_transform(x_train)\n",
    "x_std_test = sc.transform(x_test)\n",
    "#x_std_train = np.reshape(x_std_train, (x_std_train.shape[0], 1, x_std_train.shape[1])) #attempt to reshape for LSTM error, didn't work\n",
    "#x_std_test = np.reshape(x_std_test, (x_std_test.shape[0], 1, x_std_test.shape[1])) #attempt to reshape for LSTM error, didn't work\n",
    "#x_std_train = (x_train - x_train.mean())/x_train.std()\n",
    "#x_std_test = (x_test - x_test.mean())/x_test.std()\n",
    "\n",
    "\n",
    "#x_std_train = x_std_train.drop([\"open\",\"high\",\"low\",\"close\",\"volume\"], axis=1)\n",
    "#x_std_test = x_std_test.drop([\"open\",\"high\",\"low\",\"close\",\"volume\"], axis=1)\n",
    "\n",
    "print(\"X stuff\")\n",
    "print(x_std_train.shape)\n",
    "print(x_std_test.shape)\n",
    "print(x_train.shape[0]+x_test.shape[0])\n",
    "\n",
    "print(\"Y stuff\")\n",
    "print(y_train.shape)\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.275204  -3.0848251  2.3802057 ...  0.        -0.1196411  0.1197844]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "666180/666180 [==============================] - 20s 30us/step - loss: 0.3642 - mean_squared_error: 0.3642\n",
      "Epoch 2/25\n",
      "666180/666180 [==============================] - 9s 13us/step - loss: 0.3587 - mean_squared_error: 0.3587\n",
      "Epoch 3/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3566 - mean_squared_error: 0.3566\n",
      "Epoch 4/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3557 - mean_squared_error: 0.3557\n",
      "Epoch 5/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3547 - mean_squared_error: 0.3547\n",
      "Epoch 6/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3548 - mean_squared_error: 0.3548\n",
      "Epoch 7/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3548 - mean_squared_error: 0.3548\n",
      "Epoch 8/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3549 - mean_squared_error: 0.3549\n",
      "Epoch 9/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3538 - mean_squared_error: 0.3538\n",
      "Epoch 10/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3552 - mean_squared_error: 0.3552\n",
      "Epoch 11/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3540 - mean_squared_error: 0.3540\n",
      "Epoch 12/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3540 - mean_squared_error: 0.3540\n",
      "Epoch 13/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3542 - mean_squared_error: 0.3542\n",
      "Epoch 14/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3542 - mean_squared_error: 0.3542\n",
      "Epoch 15/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3544 - mean_squared_error: 0.3544\n",
      "Epoch 16/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3539 - mean_squared_error: 0.3539\n",
      "Epoch 17/25\n",
      "666180/666180 [==============================] - 5s 7us/step - loss: 0.3538 - mean_squared_error: 0.3538\n",
      "Epoch 18/25\n",
      "666180/666180 [==============================] - 5s 7us/step - loss: 0.3544 - mean_squared_error: 0.3544\n",
      "Epoch 19/25\n",
      "666180/666180 [==============================] - 5s 7us/step - loss: 0.3544 - mean_squared_error: 0.3544\n",
      "Epoch 20/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3538 - mean_squared_error: 0.3538\n",
      "Epoch 21/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3532 - mean_squared_error: 0.3532\n",
      "Epoch 22/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3533 - mean_squared_error: 0.3533\n",
      "Epoch 23/25\n",
      "666180/666180 [==============================] - 5s 8us/step - loss: 0.3536 - mean_squared_error: 0.3536\n",
      "Epoch 24/25\n",
      "666180/666180 [==============================] - 5s 7us/step - loss: 0.3542 - mean_squared_error: 0.3542\n",
      "Epoch 25/25\n",
      "666180/666180 [==============================] - 5s 7us/step - loss: 0.3537 - mean_squared_error: 0.3537\n",
      "666180/666180 [==============================] - 9s 14us/step\n",
      "\n",
      "mean_squared_error: 35.33%\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=49, activation='tanh'))\n",
    "model.add(Dense(24, activation='tanh'))\n",
    "model.add(Dense(1, activation='tanh'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x_std_train, y_train, epochs=25, batch_size=128)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(x_std_train, y_train)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "winsound.Beep(600,1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00715831]\n",
      " [-0.00508043]\n",
      " [-0.03899516]\n",
      " ...\n",
      " [-0.00546538]\n",
      " [-0.00385934]\n",
      " [-0.00816025]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_std_test)\n",
    "print(y_pred)\n",
    "\n",
    "clean_y_pred = []\n",
    "for val1 in y_pred:\n",
    "    for val2 in val1:\n",
    "        #print(val2)\n",
    "        clean_y_pred.append(val2)\n",
    "        \n",
    "print(clean_y_pred)\n",
    "print(y_test)\n",
    "\n",
    "answers_df = pd.DataFrame(\n",
    "    {#'close': close,\n",
    "     'change': y_test, # convert to changes for x_test only\n",
    "     'predictions': clean_y_pred\n",
    "    })\n",
    "\n",
    "answers_df.to_excel(\"../Data/answers_keras_btc.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.046318    0.21768869  0.1788439  ... -0.79185132  0.16684141\n",
      "   0.13907777]\n",
      " [-0.03597296 -0.04507645 -0.01055074 ...  0.80154448 -0.03037266\n",
      "   0.0086371 ]\n",
      " [-0.05263817  0.15788327  0.16579809 ... -0.702218    0.1254768\n",
      "   0.11663272]\n",
      " ...\n",
      " [-0.88766188  0.03692758  0.03072523 ...  0.3387373   0.09032996\n",
      "   0.0833828 ]\n",
      " [-0.79179994 -0.6714531  -0.55574744 ...  2.33610392 -0.71421487\n",
      "  -0.60362167]\n",
      " [-1.08555676 -0.8462395  -0.74375401 ... -1.01808666 -1.36991947\n",
      "  -0.97292207]]\n"
     ]
    }
   ],
   "source": [
    "print(x_std_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beeper(freq = 600, duration = 1000):\n",
    "    winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "import tensorflow as tf\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
