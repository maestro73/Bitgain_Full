{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\ngancitano\\AppData\\Roaming\\Python\\Python36\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# TODO: convert from \"binary on profitalbe\" to \"regression on change percent\"\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import Model\n",
    "from keras_pandas import lib\n",
    "from keras_pandas.Automater import Automater\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import stockstats as ss\n",
    "\n",
    "#import util\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import argv,exit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense,Dropout,GRU,Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential  \n",
    "from keras.layers.core import Dense, Activation  \n",
    "from keras.layers.recurrent import LSTM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def _load_data(data, n_prev=10):  \n",
    "    \"\"\"\n",
    "    data should be pd.DataFrame()\n",
    "    \"\"\"\n",
    "    docX, docY = [], []\n",
    "    for i in range(len(data)-n_prev):\n",
    "        docX.append(data.iloc[i:i+n_prev].as_matrix())\n",
    "        docY.append(data.iloc[i+n_prev].as_matrix())\n",
    "    alsX = np.array(docX)\n",
    "    alsY = np.array(docY)\n",
    "    return alsX, alsY\n",
    "\n",
    "def time_series_split(df, test_size=0.2):  \n",
    "    \"\"\"\n",
    "    This just splits data to training and testing parts\n",
    "    \"\"\"\n",
    "    ntrn = round(len(df) * (1 - test_size))\n",
    "\n",
    "    n_prex = 0\n",
    "    X_train, y_train = _load_data(df.iloc[0:ntrn])\n",
    "    X_test, y_test = _load_data(df.iloc[ntrn:])\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "FEES = 0\n",
    "def profitable(x):\n",
    "    if x[\"change\"] >= (0 + FEES):\n",
    "        return 1\n",
    "    elif x[\"change\"] <= (0 - FEES):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   timestamp    open    high     low   close  volume    change\n",
      "0        4134  1420681200  348.77  348.77  340.62  340.62    0.03 -0.020228\n",
      "1        4135  1420681260  333.73  333.73  333.73  333.73    0.01 -0.001348\n",
      "2        4136  1420681320  329.84  333.28  313.42  333.28    0.03 -0.051278\n",
      "3        4137  1420681380  273.20  316.19  273.20  316.19    0.02  0.111294\n",
      "4        4138  1420681440  323.27  351.38  323.27  351.38    0.02 -0.064546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "c:\\python36\\lib\\site-packages\\stockstats.py:387: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  lambda x: np.fabs(x - x.mean()).mean())\n",
      "c:\\python36\\lib\\site-packages\\numpy\\core\\fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "951687\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "    unnamed: 0   timestamp    open    high     low   close  volume    change  \\\n",
      "10        4144  1420681800  303.53  333.28  290.18  333.28    0.03 -0.012752   \n",
      "11        4145  1420681860  278.49  329.03  278.49  329.03    0.02 -0.030848   \n",
      "12        4146  1420681920  333.45  333.45  318.88  318.88    0.02  0.023802   \n",
      "13        4147  1420681980  328.39  328.39  326.47  326.47    0.02  0.016755   \n",
      "14        4148  1420682040  272.63  331.94  272.63  331.94    0.02 -0.059860   \n",
      "\n",
      "    close_26_ema      macd    ...            mdi      dx_14         dx  \\\n",
      "10    327.929525 -1.541712    ...      26.177437   5.151284   5.151284   \n",
      "11    328.064736 -1.207150    ...      25.466982  14.876437  14.876437   \n",
      "12    326.988746 -1.516372    ...      23.284625   9.957779   9.957779   \n",
      "13    326.930484 -1.288247    ...      21.571999   9.957779   9.957779   \n",
      "14    327.472391 -0.775171    ...      38.516206  46.858159  46.858159   \n",
      "\n",
      "     dx_6_ema        adx  adx_6_ema       adxr      trix  trix_9_sma  \\\n",
      "10  25.358428  25.358428  43.224476  43.224476 -0.201522   -0.185384   \n",
      "11  22.287746  22.287746  37.091095  37.091095 -0.198492   -0.180057   \n",
      "12  18.701644  18.701644  31.742627  31.742627 -0.202234   -0.162872   \n",
      "13  16.171520  16.171520  27.236973  27.236973 -0.196592   -0.162504   \n",
      "14  25.018750  25.018750  26.597439  26.597439 -0.177940   -0.165336   \n",
      "\n",
      "           vr  \n",
      "10  40.000000  \n",
      "11  36.363636  \n",
      "12  45.454545  \n",
      "13  54.545455  \n",
      "14  50.000000  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "#observations = lib.load_titanic()\n",
    "btc = pd.read_csv(\"../Data/coinbase_minutely.csv\")\n",
    "#btc = pd.read_csv(\"../Data/SPY_in_theory_from_1-01-00_to_1-26-19.csv\")\n",
    "print(btc.head())\n",
    "btc = ss.StockDataFrame.retype(btc) #coerces df into StockDataFrame again\n",
    "\n",
    "#calculates and appends TA indicators to stock\n",
    "\n",
    "btc['macd'] # calculate MACD indicator for the entire \"btc\" df and automatically appends to new column\n",
    "btc['volume_delta']\n",
    "btc['open_-1_r']\n",
    "btc['cr']\n",
    "btc['cr-ma1']\n",
    "btc['cr-ma2']\n",
    "btc['cr-ma3']\n",
    "btc[\"rsi_6\"]\n",
    "btc[\"rsi_12\"]\n",
    "btc[\"wr_10\"]\n",
    "btc[\"cci\"]\n",
    "btc['tr']\n",
    "btc['atr']\n",
    "btc['dma']\n",
    "btc['pdi']\n",
    "btc['mdi']\n",
    "btc['dx']\n",
    "btc['adx']\n",
    "btc['adxr']\n",
    "btc['trix']\n",
    "btc['trix_9_sma']\n",
    "btc['vr']\n",
    "btc.head()\n",
    "\n",
    "#apply profitable function then clean dataset again\n",
    "#btc[\"profitable\"] = btc.apply(profitable, axis=1) #adding column \"profitable\" where +1 represents price went up and 0 represents price went down\n",
    "#btc[\"profitable\"] = btc[\"profitable\"].shift(-1) #shifts \"profitable\" target column up 1 so current days stats predict tomorrow's profitability \n",
    "\n",
    "btc = btc[1:len(btc.index)-1] #removes first & last entry that now has NaN \"profitable\" column\n",
    "btc = btc.dropna() #removes all rows containing any NaN values\n",
    "print(len(btc))\n",
    "\n",
    "\n",
    "btc = pd.DataFrame(btc)\n",
    "change_list = btc['change'].values\n",
    "#btc = btc.drop([\"change\"], axis=1).iloc[:,1:]\n",
    "print(type(btc))\n",
    "print(btc.head())\n",
    "\n",
    "winsound.Beep(600,1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(951687, 57)\n",
      "(666180, 49)\n"
     ]
    }
   ],
   "source": [
    "print(btc.shape)\n",
    "print(x_std_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X stuff\n",
      "(666180, 49)\n",
      "(285507, 49)\n",
      "951687\n",
      "Y stuff\n",
      "(666180,)\n",
      "2.286757043591822e-05\n",
      "6.331066772443408e-06\n"
     ]
    }
   ],
   "source": [
    "#create train-test sets, then std'ize and check lengths\n",
    "\n",
    "#btc = btc.drop([\"change\"], axis=1)\n",
    "x = btc.iloc[:, 8:].values\n",
    "y = btc.iloc[:, 7].values\n",
    "#y = stock_month[\"profitable\"]\n",
    "#x = stock_month.drop([\"profitable\", \"change\"], axis=1) #move drop until after split to track data for backtesting\n",
    "\n",
    "import random\n",
    "RANDOM_STATE = 123\n",
    "random.seed(RANDOM_STATE)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = .3,random_state = RANDOM_STATE)\n",
    "'''\n",
    "training_split = 0.75\n",
    "x_train = x[:int(len(x)*training_split)]\n",
    "x_test = x[int(len(x)*training_split):]\n",
    "y_train = y[:int(len(y)*training_split)]\n",
    "y_test = y[int(len(y)*training_split):]\n",
    "'''\n",
    "sc = StandardScaler()\n",
    "x_std_train = sc.fit_transform(x_train)\n",
    "x_std_test = sc.transform(x_test)\n",
    "#x_std_train = np.reshape(x_std_train, (x_std_train.shape[0], 1, x_std_train.shape[1])) #attempt to reshape for LSTM error, didn't work\n",
    "#x_std_test = np.reshape(x_std_test, (x_std_test.shape[0], 1, x_std_test.shape[1])) #attempt to reshape for LSTM error, didn't work\n",
    "#x_std_train = (x_train - x_train.mean())/x_train.std()\n",
    "#x_std_test = (x_test - x_test.mean())/x_test.std()\n",
    "\n",
    "\n",
    "#x_std_train = x_std_train.drop([\"open\",\"high\",\"low\",\"close\",\"volume\"], axis=1)\n",
    "#x_std_test = x_std_test.drop([\"open\",\"high\",\"low\",\"close\",\"volume\"], axis=1)\n",
    "\n",
    "print(\"X stuff\")\n",
    "print(x_std_train.shape)\n",
    "print(x_std_test.shape)\n",
    "print(x_train.shape[0]+x_test.shape[0])\n",
    "\n",
    "print(\"Y stuff\")\n",
    "print(y_train.shape)\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01275204 -0.03084825  0.02380206 ...  0.         -0.00119641\n",
      "  0.00119784]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "666180/666180 [==============================] - 23s 34us/step - loss: 0.0021 - acc: 0.1691\n",
      "Epoch 2/25\n",
      "666180/666180 [==============================] - 13s 19us/step - loss: 3.6868e-04 - acc: 0.1692\n",
      "Epoch 3/25\n",
      "666180/666180 [==============================] - 13s 20us/step - loss: 3.6868e-04 - acc: 0.1692\n",
      "Epoch 4/25\n",
      "499840/666180 [=====================>........] - ETA: 4s - loss: 2.9044e-04 - acc: 0.1688"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=49, activation='relu'))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x_std_train, y_train, epochs=25, batch_size=128)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(x_std_train, y_train)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "winsound.Beep(600,1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4931231 ]\n",
      " [0.7233376 ]\n",
      " [0.5378216 ]\n",
      " ...\n",
      " [0.80010986]\n",
      " [0.542126  ]\n",
      " [0.5579175 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-31d635c44de5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     {#'close': close,\n\u001b[0;32m     14\u001b[0m      \u001b[1;34m'change'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mchange_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m      \u001b[1;34m'predictions'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mclean_y_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     })\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    346\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[1;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    457\u001b[0m             \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m   7354\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7356\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7358\u001b[0m     \u001b[1;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   7400\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7401\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7402\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'arrays must all be same length'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7404\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_std_test)\n",
    "print(y_pred)\n",
    "\n",
    "clean_y_pred = []\n",
    "for val1 in y_pred:\n",
    "    for val2 in val1:\n",
    "        #print(val2)\n",
    "        clean_y_pred.append(val2)\n",
    "        \n",
    "print(clean_y_pred)\n",
    "\n",
    "answers_df = pd.DataFrame(\n",
    "    {#'close': close,\n",
    "     'change': change_list, # convert to changes for x_test only\n",
    "     'predictions': clean_y_pred\n",
    "    })\n",
    "\n",
    "answers_df.to_excel(\"../Data/answers_keras_btc.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.046318    0.21768869  0.1788439  ... -0.79185132  0.16684141\n",
      "   0.13907777]\n",
      " [-0.03597296 -0.04507645 -0.01055074 ...  0.80154448 -0.03037266\n",
      "   0.0086371 ]\n",
      " [-0.05263817  0.15788327  0.16579809 ... -0.702218    0.1254768\n",
      "   0.11663272]\n",
      " ...\n",
      " [-0.88766188  0.03692758  0.03072523 ...  0.3387373   0.09032996\n",
      "   0.0833828 ]\n",
      " [-0.79179994 -0.6714531  -0.55574744 ...  2.33610392 -0.71421487\n",
      "  -0.60362167]\n",
      " [-1.08555676 -0.8462395  -0.74375401 ... -1.01808666 -1.36991947\n",
      "  -0.97292207]]\n"
     ]
    }
   ],
   "source": [
    "print(x_std_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beeper(freq = 600, duration = 1000):\n",
    "    winsound.Beep(freq, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
